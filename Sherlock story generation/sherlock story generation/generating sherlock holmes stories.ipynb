{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a82161ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ankita\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ac4dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 215021\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "story_path = os.path.join(current_directory, \"sherlock\")\n",
    "\n",
    "def read_all_stories(story_path):\n",
    "    txt = []\n",
    "    for _, _, files in os.walk(story_path):\n",
    "        for file in files:\n",
    "            with open(os.path.join(story_path, file), 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line == '----------': \n",
    "                        break\n",
    "                    if line != '':\n",
    "                        txt.append(line)\n",
    "    return txt\n",
    "\n",
    "stories = read_all_stories(story_path)\n",
    "print(\"Number of lines:\", len(stories))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c950b",
   "metadata": {},
   "source": [
    "Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(txt):\n",
    "    cleaned_txt = []\n",
    "    for line in txt:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
    "        tokens = word_tokenize(line)\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        cleaned_txt+=words\n",
    "    return cleaned_txt\n",
    "\n",
    "cleaned_stories = clean_txt(stories)\n",
    "print(\"number of words = \", len(cleaned_stories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3d0263",
   "metadata": {},
   "source": [
    "# Creating the markov model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17759e9",
   "metadata": {},
   "source": [
    "This function `make_markov_model` creates a Markov chain model based on the provided text data (`cleaned_stories`). Here's a breakdown of how it works:\n",
    "\n",
    "1. **Initialization**: It initializes an empty dictionary `markov_model` to store the Markov chain transitions.\n",
    "\n",
    "2. **Iteration through the Text**: It iterates over the cleaned text data (`cleaned_stories`) to extract sequences of tokens to build the Markov model. The iteration is performed up to `len(cleaned_stories) - n_gram - 1`, where `n_gram` is the length of the sequence of tokens considered for each transition. For example, if `n_gram=2`, it considers pairs of consecutive words.\n",
    "\n",
    "3. **Building States and Transitions**:\n",
    "   - Inside the loop, it initializes `curr_state` and `next_state` as empty strings.\n",
    "   - It iterates `n_gram` times to concatenate the next `n_gram` tokens to form the current state and the next state.\n",
    "   - For example, if `n_gram=2`, it considers pairs of consecutive words. So, `curr_state` will contain the current word and the next word, and `next_state` will contain the next word and the word after that.\n",
    "   - It then checks if the `curr_state` exists in the `markov_model` dictionary. If not, it initializes it and sets the count for the `next_state` to 1. If it already exists, it increments the count for the `next_state`.\n",
    "\n",
    "4. **Calculating Transition Probabilities**:\n",
    "   - After counting the occurrences of transitions, it calculates the transition probabilities.\n",
    "   - For each current state (`curr_state`) in the `markov_model`, it sums up the counts of all possible transitions.\n",
    "   - Then, it normalizes the counts by dividing each count by the total count for that current state. This results in transition probabilities.\n",
    "   - This step ensures that the probabilities of transitions from each state sum up to 1, as required by a Markov chain model.\n",
    "\n",
    "5. **Return**: Finally, it returns the completed Markov chain model (`markov_model`), where each state maps to a dictionary of next states along with their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e2858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_markov_model(cleaned_stories, n_gram=2):\n",
    "    markov_model = {}\n",
    "    for i in range(len(cleaned_stories)-n_gram-1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
    "        curr_state = curr_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {}\n",
    "            markov_model[curr_state][next_state] = 1\n",
    "        else:\n",
    "            if next_state in markov_model[curr_state]:\n",
    "                markov_model[curr_state][next_state] += 1\n",
    "            else:\n",
    "                markov_model[curr_state][next_state] = 1\n",
    "    \n",
    "    # calculating transition probabilities\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count/total\n",
    "        \n",
    "    return markov_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac2e80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model = make_markov_model(cleaned_stories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcafb0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of states =  208670\n"
     ]
    }
   ],
   "source": [
    "print(\"number of states = \", len(markov_model.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3998323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible transitions from 'the game' state: \n",
      "\n",
      "{'your letter': 0.02702702702702703, 'was up': 0.09009009009009009, 'is afoot': 0.036036036036036036, 'for the': 0.036036036036036036, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'would have': 0.036036036036036036, 'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'in their': 0.036036036036036036, 'was whist': 0.036036036036036036, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'was afoot': 0.036036036036036036, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703}\n"
     ]
    }
   ],
   "source": [
    "print(\"All possible transitions from 'the game' state: \\n\")\n",
    "print(markov_model['the game'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d581da3",
   "metadata": {},
   "source": [
    "# Generating Sherlock Holmes stories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f944f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(markov_model, limit=100, start='my god'):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story+=curr_state+\" \"\n",
    "    while n<limit:\n",
    "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
    "                                    list(markov_model[curr_state].values()))\n",
    "        \n",
    "        curr_state = next_state[0]\n",
    "        story+=curr_state+\" \"\n",
    "        n+=1\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c6cacb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  dear holmes oh yes said he the fact that if ever again i have spoiled him very likely \n",
      "1.  dear holmes i fear that we could prove from peter careys evidence how these securities came on the \n",
      "2.  dear holmes my previous letters and supposing that the name of our main inquiry it would not do \n",
      "3.  dear holmes i fear that the emerald pin will forever recall to my friends eyes yet the scene \n",
      "4.  dear holmes i ejaculated surely said i the honour to be the consequence if i failed to catch \n",
      "5.  dear holmes i exclaimed devoutly but you were not yourself think that ill take it now for i \n",
      "6.  dear holmes i ejaculated no no we must put the investigation into their hands had kept him in \n",
      "7.  dear holmes it is absurd to anyone who may follow him on each side of the british public \n",
      "8.  dear holmes you are very busy just now i trust that age doth not wither nor custom stale \n",
      "9.  dear holmes i thought that as it was of all the trouble i had doubts as he spoke \n",
      "10.  dear holmes i fear that you would not give two minutes of conscious sensation to anyone my motive \n",
      "11.  dear holmes i have to carry him down and as far off by the throat but i struck \n",
      "12.  dear holmes if i did not know i am sorry that we have traced the evil to its \n",
      "13.  dear holmes i exclaimed perhaps one of those undiscovered crimes in which i had examined the hall and \n",
      "14.  dear holmes am i charged with with making away with a look at it with my back like \n",
      "15.  dear holmes i exclaimed i could rest until it killed him some time before i could also besides \n",
      "16.  dear holmes if i am any judge well have you there are certainly one of the existence of \n",
      "17.  dear holmes oh yes mother is alive oh yes mother is alive and well there ive said enough \n",
      "18.  dear holmes what do you mean that your double was at work upon him and what did he \n",
      "19.  dear holmes he has used for this particular business the conclusions of every department are passed to him \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"dear holmes\", limit=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f96133f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  my dear watson he led me out to you since you are too late to prevent him from \n",
      "1.  my dear holmes i am an interpreter as perhaps my life my dear fellow there is always romance \n",
      "2.  my dear watson that that does he and he watched us with infinite skill and delicacy in his \n",
      "3.  my dear watson and that is one point on which i should like a magician said she how \n",
      "4.  my dear watson you know something of this horrible affair in the appearance of our room i had \n",
      "5.  my dear watson your revolver has solved the house was an empty house which had such a day \n",
      "6.  my dear daughter alice and spoke excellent english having served its purpose would be with him to restore \n",
      "7.  my dear fellow you see exactly the same cold and inexorable manner showed the entrance to his bedroom \n",
      "8.  my dear watson i suppose you must not grudge me a little clearer if you can understand said \n",
      "9.  my dear watson that this is insanity holmes only two days yes yes of course it has moved \n",
      "10.  my dear watson but now we have to do is to carry out your assertion no i have \n",
      "11.  my dear watson yet another had the volume from the accusation the least that is so remarkable that \n",
      "12.  my dear daughter alice and spoke to her husband oh yes said hopkins i have investigated many crimes \n",
      "13.  my dear watson professor moriarty is not a gang of murderers whose minds had suffered such complete moral \n",
      "14.  my dear watson i suppose when you doctored you found some place of shelter and let me expound \n",
      "15.  my dear watson said he we have been branded there it was one it was above the usual \n",
      "16.  my dear fellow said stanley hopkins swore between his teeth and whistled and sang at his rather wild \n",
      "17.  my dear young lady at the bell watson and as the boat was now proceeding slowly onward again \n",
      "18.  my dear holmes he was looking for something since he had not perceived him and his identity had \n",
      "19.  my dear watson that there were steps in the road they declare that no robbery has been committed \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"my dear\", limit=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd9ce54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  i would stay to show you first how it was on a boulder and rested his chin in \n",
      "1.  i would not miss it for the sake of it as any and though we shall keep you \n",
      "2.  i would carry my stone to beat out his brains with but cooee is a distinctly australian cry \n",
      "3.  i would hardly go so far i could find in his pockets we have been married about seven \n",
      "4.  i would ask you lord holdhurst lord holdhurst the cabinet was informed that captain morstan was then to \n",
      "5.  i would ask the inspector to send up wiggins alone to report and the third from london from \n",
      "6.  i would leave her lying wounded upon the handiwork of a very active gentleman not older than yourself \n",
      "7.  i would break the sentence up into words and putting on his nose endeavoured to read in his \n",
      "8.  i would play the question now is about the richest heiress in england surely it was for lady \n",
      "9.  i would have been an evil smile upon his face but it is impossible admirable he said a \n",
      "10.  i would be accused in their stead and we are at chislehurst station and i am a very \n",
      "11.  i would call he looked from one to the other hand were most bitter enemy a rascally fellow \n",
      "12.  i would respond to the flattering demand and to explain to you sir turning upon me there is \n",
      "13.  i would dream of trying said he then you have come i am going out to my companions \n",
      "14.  i would break the monotony of my daily existence under these circumstances i still seemed to me something \n",
      "15.  i would risk a little sporting flutter that you dont believe such nonsense as that said he it \n",
      "16.  i would not give immediate notice of their debate i wish none of their pictures libraries or plate \n",
      "17.  i would always be the master has rolled up his hand in these parts as brother baldwin knows \n",
      "18.  i would just ask ye when we want you a very earnest in what they do their work \n",
      "19.  i would not brawl in the utter silence i heard vaguely that his abilities i am on the \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"i would\", limit=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f7644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
